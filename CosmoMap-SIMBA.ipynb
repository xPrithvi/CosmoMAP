{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3f7ea45-e034-4f5f-ac08-13578f759c4f",
   "metadata": {},
   "source": [
    "# CosmoMap SIMBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9d44651-c79b-4899-b091-9914edc69f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch imports,\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchinfo import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5727e676-4076-4195-bae2-0f012406798d",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14344246-9d26-4408-8e06-b56adad50d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = torch.load(\"train.pt\")\n",
    "test_data = torch.load(\"test.pt\")\n",
    "validation_data = torch.load(\"validation.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e0ef8d-5a70-4a3e-9b2c-40b11088f1e4",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0134a2df-66f7-4ac9-88e1-cf2992c610a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"Class for the neural network architecture using upsampling instead of deconvolution.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Constructor method which builds the layers of the neural network.\"\"\"\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # Replication padding,\n",
    "        self.pad = nn.ReplicationPad3d(1)\n",
    "\n",
    "        # Feature extraction layers\n",
    "        self.conv1 = nn.Conv3d(1, 8, kernel_size=3, padding=0) \n",
    "        self.conv2 = nn.Conv3d(8, 16, kernel_size=3, padding=0) \n",
    "        self.conv3 = nn.Conv3d(16, 32, kernel_size=3, padding=0) \n",
    "        self.conv4 = nn.Conv3d(32, 16, kernel_size=3, padding=0) \n",
    "        self.conv5 = nn.Conv3d(16, 8, kernel_size=3, padding=0) \n",
    "        self.conv6 = nn.Conv3d(8, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass of the neural network.\"\"\"\n",
    "\n",
    "        x = self.pad(x)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pad(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pad(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pad(x)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pad(x)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = self.conv6(x)\n",
    "\n",
    "        return F.sigmoid(x)\n",
    "\n",
    "def initialise_weights(model):\n",
    "    \"\"\"Applies custom weight initialization to Conv3D layers.\"\"\"\n",
    "    if isinstance(model, nn.Conv3d):\n",
    "        torch.nn.init.kaiming_uniform_(model.weight, nonlinearity='relu')\n",
    "        if model.bias is not None:\n",
    "            torch.nn.init.constant_(model.bias, 0)  # Set biases to zero\n",
    "\n",
    "class WeightedMSELoss(nn.Module):\n",
    "    \"\"\"Custom loss function to deal with data sparsity issue.\"\"\"\n",
    "    def __init__(self, alpha=1.0):\n",
    "        super(WeightedMSELoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        weights = torch.abs(targets) ** self.alpha\n",
    "        loss = weights * (preds - targets) ** 2\n",
    "        return loss.mean()\n",
    "\n",
    "def compute_validation_loss(validation_data):\n",
    "\n",
    "    # Switching model to eval mode,\n",
    "    model.eval()\n",
    "\n",
    "    # Loading validation data set,\n",
    "    input_grids = validation_data[0]\n",
    "    target_grids = validation_data[1]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        input_grids = input_grids.to(device)\n",
    "        output_grids = model(input_grids)\n",
    "\n",
    "    validation_loss = loss_function(output_grids, target_grids)\n",
    "\n",
    "    return validation_loss\n",
    "\n",
    "def train_model(training_data, epochs, lr, current_epoch):\n",
    "\n",
    "    \"\"\"TRAINING LOOP\"\"\"\n",
    "\n",
    "    # Single training iteration,\n",
    "    for batch_idx, (input_data, target) in enumerate(training_data):\n",
    "        input_data, target = input_data.to(device), target.to(device)\n",
    "\n",
    "        # Forward pass,\n",
    "        output = model(input_data)\n",
    "    \n",
    "        # Calculating loss,\n",
    "        loss = loss_function(output, target)\n",
    "\n",
    "        # Backpropagation,\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "    # Compute validation loss,\n",
    "    val_loss = compute_validation_loss(validation_data)\n",
    "\n",
    "    # Printing,\n",
    "    print(f\"Epoch: {current_epoch}, Training Loss: {loss.item()}, Validation Loss: {val_loss.item()}\")                                                                                                                                                                                                                                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ccba1e8-9149-474f-a7af-3a6c1aea1ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Device: cpu\n",
      "Epoch: 1, Training Loss: 0.001539055840112269, Validation Loss: 5.362833803701506e-07\n",
      "Epoch: 2, Training Loss: 0.0010723627638071775, Validation Loss: 5.33860259110952e-07\n",
      "Epoch: 3, Training Loss: 0.001084979623556137, Validation Loss: 5.283640689413005e-07\n",
      "Epoch: 4, Training Loss: 0.0010407083900645375, Validation Loss: 5.234020932221028e-07\n",
      "Epoch: 5, Training Loss: 0.0010175611823797226, Validation Loss: 5.194180516809865e-07\n",
      "Epoch: 6, Training Loss: 0.0007241687853820622, Validation Loss: 5.169706014385156e-07\n",
      "Epoch: 7, Training Loss: 0.0009893898386508226, Validation Loss: 5.139526706443576e-07\n",
      "Epoch: 8, Training Loss: 0.001012943685054779, Validation Loss: 5.105713398734224e-07\n",
      "Epoch: 9, Training Loss: 0.0005665794597007334, Validation Loss: 5.076565798844968e-07\n",
      "Epoch: 10, Training Loss: 0.0010219445684924722, Validation Loss: 5.052699521002069e-07\n",
      "Epoch: 11, Training Loss: 0.0009881663136184216, Validation Loss: 5.033318188907288e-07\n",
      "Epoch: 12, Training Loss: 0.0005968099576421082, Validation Loss: 5.01372312555759e-07\n",
      "Epoch: 13, Training Loss: 0.0009447232005186379, Validation Loss: 4.996157372261223e-07\n",
      "Epoch: 14, Training Loss: 0.0005727546522393823, Validation Loss: 4.967766926711192e-07\n",
      "Epoch: 15, Training Loss: 0.0009459684952162206, Validation Loss: 4.947915499542432e-07\n",
      "Epoch: 16, Training Loss: 0.000941657111980021, Validation Loss: 4.9402427748646e-07\n",
      "Epoch: 17, Training Loss: 0.0009046483901329339, Validation Loss: 4.934275921186781e-07\n",
      "Epoch: 18, Training Loss: 0.000599171151407063, Validation Loss: 4.90775619255146e-07\n",
      "Epoch: 19, Training Loss: 0.0008732341811992228, Validation Loss: 4.879559014625556e-07\n",
      "Epoch: 20, Training Loss: 0.000511770776938647, Validation Loss: 4.837725668949133e-07\n",
      "Epoch: 21, Training Loss: 0.0009136013686656952, Validation Loss: 4.820255412596453e-07\n",
      "Epoch: 22, Training Loss: 0.000902356521692127, Validation Loss: 4.824873371944705e-07\n",
      "Epoch: 23, Training Loss: 0.0004880054038949311, Validation Loss: 4.812859515368473e-07\n",
      "Epoch: 24, Training Loss: 0.0008284064242616296, Validation Loss: 4.802027433470357e-07\n",
      "Epoch: 25, Training Loss: 0.0005247181397862732, Validation Loss: 4.764119410083367e-07\n"
     ]
    }
   ],
   "source": [
    "# HYPERPARAMETERS\n",
    "LEARNING_RATE = 1e-3\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 25\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Load model and optimiser,\n",
    "    model = Net()\n",
    "    optimiser = optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "\n",
    "    # Weight initialisation,\n",
    "    model.apply(initialise_weights)\n",
    "\n",
    "    # Checking for CUDA,\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"\")\n",
    "    print(f\"Device: {device}\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Creating loss function,\n",
    "    loss_function = WeightedMSELoss(alpha=2.5)\n",
    "\n",
    "    # Load data,\n",
    "    training_data_loaded = DataLoader(training_data,\n",
    "                                      batch_size = BATCH_SIZE,\n",
    "                                      shuffle = True,\n",
    "                                      num_workers = 1)\n",
    "\n",
    "    \"\"\"TRAINING LOOP\"\"\"\n",
    "\n",
    "    # Switching model into training mode,\n",
    "    model.train()\n",
    "\n",
    "    # Begin training,\n",
    "    for epoch in range(1, (EPOCHS + 1)):\n",
    "        train_model(training_data = training_data_loaded, epochs = EPOCHS, lr = LEARNING_RATE, current_epoch = epoch)\n",
    "\n",
    "        # Creating checkpoint,\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimiser.state_dict(),\n",
    "            'loss': loss_function\n",
    "        }\n",
    "\n",
    "        # Saving checkpoint,\n",
    "        torch.save(checkpoint, f\"checkpoint_epoch_{epoch}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2eb88d02-9c2f-4979-b92d-b89e614744ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put model into evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Loading grid,\n",
    "i = 6\n",
    "\n",
    "# We must unsqueeze (batch_size = 1),\n",
    "input_grid = test_data[0][i].unsqueeze(dim = 0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    input_grid = input_grid.to(device)\n",
    "    output_grid = model(input_grid)\n",
    "\n",
    "# Squeezing the data and converting to NumPy arrays,\n",
    "data_input = input_grid.squeeze(dim = 0).squeeze(dim = 0).detach().numpy()\n",
    "prediction = output_grid.squeeze(dim = 0).squeeze(dim = 0).detach().numpy()\n",
    "target = test_data[1][i].squeeze(dim = 0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "981f21bd-a6dd-4fc0-9199-ef93206650ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b6a09ee6da4e02bd988d786f5f93a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0, description='Slice', max=31)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a72164c9aef247cc8429cfecaa74c886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_slice(i, grid0, grid1, grid2):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 6))  # Two side-by-side plots\n",
    "\n",
    "    # Plot zeroth grid,\n",
    "    img0 = axes[0].imshow(grid0[i], cmap=\"rainbow\")\n",
    "    axes[0].set_title(\"Input\")\n",
    "    axes[0].set_xlabel(\"(Mpc/h)\")\n",
    "    axes[0].set_ylabel(\"(Mpc/h)\")\n",
    "\n",
    "    # Plot first grid,\n",
    "    img1 = axes[1].imshow(grid1[i], cmap=\"rainbow\")\n",
    "    axes[1].set_title(\"Prediction\")\n",
    "    axes[1].set_xlabel(\"(Mpc/h)\")\n",
    "    axes[1].set_ylabel(\"(Mpc/h)\")\n",
    "\n",
    "    # Plot second grid,\n",
    "    img2 = axes[2].imshow(grid2[i], cmap=\"rainbow\")\n",
    "    axes[2].set_title(\"Target\")\n",
    "    axes[2].set_xlabel(\"(Mpc/h)\")\n",
    "    axes[2].set_ylabel(\"(Mpc/h)\")\n",
    "\n",
    "    # Custom tick formatter function\n",
    "    def custom_formatter(x, pos):\n",
    "        return f'{x*25}'\n",
    "\n",
    "    formatter = FuncFormatter(custom_formatter)\n",
    "    for ax in axes:\n",
    "        ax.xaxis.set_major_formatter(formatter)\n",
    "        ax.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "    # Add color bars\n",
    "    fig.colorbar(img0, ax=axes[0], orientation=\"vertical\")\n",
    "    fig.colorbar(img1, ax=axes[1], orientation=\"vertical\")\n",
    "    fig.colorbar(img2, ax=axes[2], orientation=\"vertical\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Creating slider widget,\n",
    "grid0 = data_input\n",
    "grid1 = prediction\n",
    "grid2 = target  \n",
    "\n",
    "grid_zlength = (grid1.shape[2] - 1)\n",
    "slider = widgets.IntSlider(min=0, max=grid_zlength, value=0, description=\"Slice\")\n",
    "\n",
    "# Link slider to function,\n",
    "output = widgets.interactive_output(lambda i: plot_slice(i, grid0, grid1, grid2), {'i': slider})\n",
    "\n",
    "# Display slider and plot,\n",
    "display(slider, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6a8526-23c4-4a34-a5a2-2a9109e6580c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
